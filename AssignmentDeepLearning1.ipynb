{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(10):\n",
    "    # Find the first instance of each class\n",
    "    class_idx = np.where(train_labels == i)[0][0]\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[class_idx], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n",
       "          1,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n",
       "          0,   3],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n",
       "          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n",
       "         10,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n",
       "         72,  15],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n",
       "        172,  66],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n",
       "        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n",
       "        229,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n",
       "        173,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n",
       "        202,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n",
       "        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n",
       "        209,  52],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n",
       "        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n",
       "        167,  56],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n",
       "        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n",
       "         92,   0],\n",
       "       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n",
       "        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n",
       "         77,   0],\n",
       "       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n",
       "        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n",
       "        159,   0],\n",
       "       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n",
       "        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n",
       "        215,   0],\n",
       "       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n",
       "        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n",
       "        246,   0],\n",
       "       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n",
       "         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n",
       "        225,   0],\n",
       "       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n",
       "        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n",
       "        229,  29],\n",
       "       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n",
       "        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n",
       "        230,  67],\n",
       "       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n",
       "        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n",
       "        206, 115],\n",
       "       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n",
       "        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n",
       "        210,  92],\n",
       "       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n",
       "        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n",
       "        170,   0],\n",
       "       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n",
       "        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images[..., tf.newaxis]\n",
    "test_images = test_images[..., tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.05098039],\n",
       "        [0.28627452],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.01568628],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.00392157],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.01176471],\n",
       "        [0.        ],\n",
       "        [0.14117648],\n",
       "        [0.53333336],\n",
       "        [0.49803922],\n",
       "        [0.24313726],\n",
       "        [0.21176471],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.01176471],\n",
       "        [0.01568628],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.01176471]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.02352941],\n",
       "        [0.        ],\n",
       "        [0.4       ],\n",
       "        [0.8       ],\n",
       "        [0.6901961 ],\n",
       "        [0.5254902 ],\n",
       "        [0.5647059 ],\n",
       "        [0.48235294],\n",
       "        [0.09019608],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.04705882],\n",
       "        [0.03921569],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.60784316],\n",
       "        [0.9254902 ],\n",
       "        [0.8117647 ],\n",
       "        [0.69803923],\n",
       "        [0.41960785],\n",
       "        [0.6117647 ],\n",
       "        [0.6313726 ],\n",
       "        [0.42745098],\n",
       "        [0.2509804 ],\n",
       "        [0.09019608],\n",
       "        [0.3019608 ],\n",
       "        [0.50980395],\n",
       "        [0.28235295],\n",
       "        [0.05882353]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.        ],\n",
       "        [0.27058825],\n",
       "        [0.8117647 ],\n",
       "        [0.8745098 ],\n",
       "        [0.85490197],\n",
       "        [0.84705883],\n",
       "        [0.84705883],\n",
       "        [0.6392157 ],\n",
       "        [0.49803922],\n",
       "        [0.4745098 ],\n",
       "        [0.47843137],\n",
       "        [0.57254905],\n",
       "        [0.5529412 ],\n",
       "        [0.34509805],\n",
       "        [0.6745098 ],\n",
       "        [0.25882354]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.00392157],\n",
       "        [0.00392157],\n",
       "        [0.        ],\n",
       "        [0.78431374],\n",
       "        [0.9098039 ],\n",
       "        [0.9098039 ],\n",
       "        [0.9137255 ],\n",
       "        [0.8980392 ],\n",
       "        [0.8745098 ],\n",
       "        [0.8745098 ],\n",
       "        [0.84313726],\n",
       "        [0.8352941 ],\n",
       "        [0.6431373 ],\n",
       "        [0.49803922],\n",
       "        [0.48235294],\n",
       "        [0.76862746],\n",
       "        [0.8980392 ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.7176471 ],\n",
       "        [0.88235295],\n",
       "        [0.84705883],\n",
       "        [0.8745098 ],\n",
       "        [0.89411765],\n",
       "        [0.92156863],\n",
       "        [0.8901961 ],\n",
       "        [0.8784314 ],\n",
       "        [0.87058824],\n",
       "        [0.8784314 ],\n",
       "        [0.8666667 ],\n",
       "        [0.8745098 ],\n",
       "        [0.9607843 ],\n",
       "        [0.6784314 ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.75686276],\n",
       "        [0.89411765],\n",
       "        [0.85490197],\n",
       "        [0.8352941 ],\n",
       "        [0.7764706 ],\n",
       "        [0.7058824 ],\n",
       "        [0.83137256],\n",
       "        [0.8235294 ],\n",
       "        [0.827451  ],\n",
       "        [0.8352941 ],\n",
       "        [0.8745098 ],\n",
       "        [0.8627451 ],\n",
       "        [0.9529412 ],\n",
       "        [0.7921569 ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.01176471],\n",
       "        [0.        ],\n",
       "        [0.04705882],\n",
       "        [0.85882354],\n",
       "        [0.8627451 ],\n",
       "        [0.83137256],\n",
       "        [0.85490197],\n",
       "        [0.7529412 ],\n",
       "        [0.6627451 ],\n",
       "        [0.8901961 ],\n",
       "        [0.8156863 ],\n",
       "        [0.85490197],\n",
       "        [0.8784314 ],\n",
       "        [0.83137256],\n",
       "        [0.8862745 ],\n",
       "        [0.77254903],\n",
       "        [0.81960785],\n",
       "        [0.20392157]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.02352941],\n",
       "        [0.        ],\n",
       "        [0.3882353 ],\n",
       "        [0.95686275],\n",
       "        [0.87058824],\n",
       "        [0.8627451 ],\n",
       "        [0.85490197],\n",
       "        [0.79607844],\n",
       "        [0.7764706 ],\n",
       "        [0.8666667 ],\n",
       "        [0.84313726],\n",
       "        [0.8352941 ],\n",
       "        [0.87058824],\n",
       "        [0.8627451 ],\n",
       "        [0.9607843 ],\n",
       "        [0.46666667],\n",
       "        [0.654902  ],\n",
       "        [0.21960784]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.01568628],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.21568628],\n",
       "        [0.9254902 ],\n",
       "        [0.89411765],\n",
       "        [0.9019608 ],\n",
       "        [0.89411765],\n",
       "        [0.9411765 ],\n",
       "        [0.9098039 ],\n",
       "        [0.8352941 ],\n",
       "        [0.85490197],\n",
       "        [0.8745098 ],\n",
       "        [0.91764706],\n",
       "        [0.8509804 ],\n",
       "        [0.8509804 ],\n",
       "        [0.81960785],\n",
       "        [0.36078432],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.01568628],\n",
       "        [0.02352941],\n",
       "        [0.02745098],\n",
       "        [0.00784314],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.92941177],\n",
       "        [0.8862745 ],\n",
       "        [0.8509804 ],\n",
       "        [0.8745098 ],\n",
       "        [0.87058824],\n",
       "        [0.85882354],\n",
       "        [0.87058824],\n",
       "        [0.8666667 ],\n",
       "        [0.84705883],\n",
       "        [0.8745098 ],\n",
       "        [0.8980392 ],\n",
       "        [0.84313726],\n",
       "        [0.85490197],\n",
       "        [1.        ],\n",
       "        [0.3019608 ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.01176471],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.24313726],\n",
       "        [0.5686275 ],\n",
       "        [0.8       ],\n",
       "        [0.89411765],\n",
       "        [0.8117647 ],\n",
       "        [0.8352941 ],\n",
       "        [0.8666667 ],\n",
       "        [0.85490197],\n",
       "        [0.8156863 ],\n",
       "        [0.827451  ],\n",
       "        [0.85490197],\n",
       "        [0.8784314 ],\n",
       "        [0.8745098 ],\n",
       "        [0.85882354],\n",
       "        [0.84313726],\n",
       "        [0.8784314 ],\n",
       "        [0.95686275],\n",
       "        [0.62352943],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.07058824],\n",
       "        [0.17254902],\n",
       "        [0.32156864],\n",
       "        [0.41960785],\n",
       "        [0.7411765 ],\n",
       "        [0.89411765],\n",
       "        [0.8627451 ],\n",
       "        [0.87058824],\n",
       "        [0.8509804 ],\n",
       "        [0.8862745 ],\n",
       "        [0.78431374],\n",
       "        [0.8039216 ],\n",
       "        [0.827451  ],\n",
       "        [0.9019608 ],\n",
       "        [0.8784314 ],\n",
       "        [0.91764706],\n",
       "        [0.6901961 ],\n",
       "        [0.7372549 ],\n",
       "        [0.98039216],\n",
       "        [0.972549  ],\n",
       "        [0.9137255 ],\n",
       "        [0.93333334],\n",
       "        [0.84313726],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.22352941],\n",
       "        [0.73333335],\n",
       "        [0.8156863 ],\n",
       "        [0.8784314 ],\n",
       "        [0.8666667 ],\n",
       "        [0.8784314 ],\n",
       "        [0.8156863 ],\n",
       "        [0.8       ],\n",
       "        [0.8392157 ],\n",
       "        [0.8156863 ],\n",
       "        [0.81960785],\n",
       "        [0.78431374],\n",
       "        [0.62352943],\n",
       "        [0.9607843 ],\n",
       "        [0.75686276],\n",
       "        [0.80784315],\n",
       "        [0.8745098 ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [0.8666667 ],\n",
       "        [0.91764706],\n",
       "        [0.8666667 ],\n",
       "        [0.827451  ],\n",
       "        [0.8627451 ],\n",
       "        [0.9098039 ],\n",
       "        [0.9647059 ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.01176471],\n",
       "        [0.7921569 ],\n",
       "        [0.89411765],\n",
       "        [0.8784314 ],\n",
       "        [0.8666667 ],\n",
       "        [0.827451  ],\n",
       "        [0.827451  ],\n",
       "        [0.8392157 ],\n",
       "        [0.8039216 ],\n",
       "        [0.8039216 ],\n",
       "        [0.8039216 ],\n",
       "        [0.8627451 ],\n",
       "        [0.9411765 ],\n",
       "        [0.3137255 ],\n",
       "        [0.5882353 ],\n",
       "        [1.        ],\n",
       "        [0.8980392 ],\n",
       "        [0.8666667 ],\n",
       "        [0.7372549 ],\n",
       "        [0.6039216 ],\n",
       "        [0.7490196 ],\n",
       "        [0.8235294 ],\n",
       "        [0.8       ],\n",
       "        [0.81960785],\n",
       "        [0.87058824],\n",
       "        [0.89411765],\n",
       "        [0.88235295],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.38431373],\n",
       "        [0.9137255 ],\n",
       "        [0.7764706 ],\n",
       "        [0.8235294 ],\n",
       "        [0.87058824],\n",
       "        [0.8980392 ],\n",
       "        [0.8980392 ],\n",
       "        [0.91764706],\n",
       "        [0.9764706 ],\n",
       "        [0.8627451 ],\n",
       "        [0.7607843 ],\n",
       "        [0.84313726],\n",
       "        [0.8509804 ],\n",
       "        [0.94509804],\n",
       "        [0.25490198],\n",
       "        [0.28627452],\n",
       "        [0.41568628],\n",
       "        [0.45882353],\n",
       "        [0.65882355],\n",
       "        [0.85882354],\n",
       "        [0.8666667 ],\n",
       "        [0.84313726],\n",
       "        [0.8509804 ],\n",
       "        [0.8745098 ],\n",
       "        [0.8745098 ],\n",
       "        [0.8784314 ],\n",
       "        [0.8980392 ],\n",
       "        [0.11372549]],\n",
       "\n",
       "       [[0.29411766],\n",
       "        [0.8       ],\n",
       "        [0.83137256],\n",
       "        [0.8       ],\n",
       "        [0.75686276],\n",
       "        [0.8039216 ],\n",
       "        [0.827451  ],\n",
       "        [0.88235295],\n",
       "        [0.84705883],\n",
       "        [0.7254902 ],\n",
       "        [0.77254903],\n",
       "        [0.80784315],\n",
       "        [0.7764706 ],\n",
       "        [0.8352941 ],\n",
       "        [0.9411765 ],\n",
       "        [0.7647059 ],\n",
       "        [0.8901961 ],\n",
       "        [0.9607843 ],\n",
       "        [0.9372549 ],\n",
       "        [0.8745098 ],\n",
       "        [0.85490197],\n",
       "        [0.83137256],\n",
       "        [0.81960785],\n",
       "        [0.87058824],\n",
       "        [0.8627451 ],\n",
       "        [0.8666667 ],\n",
       "        [0.9019608 ],\n",
       "        [0.2627451 ]],\n",
       "\n",
       "       [[0.1882353 ],\n",
       "        [0.79607844],\n",
       "        [0.7176471 ],\n",
       "        [0.7607843 ],\n",
       "        [0.8352941 ],\n",
       "        [0.77254903],\n",
       "        [0.7254902 ],\n",
       "        [0.74509805],\n",
       "        [0.7607843 ],\n",
       "        [0.7529412 ],\n",
       "        [0.7921569 ],\n",
       "        [0.8392157 ],\n",
       "        [0.85882354],\n",
       "        [0.8666667 ],\n",
       "        [0.8627451 ],\n",
       "        [0.9254902 ],\n",
       "        [0.88235295],\n",
       "        [0.84705883],\n",
       "        [0.78039217],\n",
       "        [0.80784315],\n",
       "        [0.7294118 ],\n",
       "        [0.70980394],\n",
       "        [0.69411767],\n",
       "        [0.6745098 ],\n",
       "        [0.70980394],\n",
       "        [0.8039216 ],\n",
       "        [0.80784315],\n",
       "        [0.4509804 ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.47843137],\n",
       "        [0.85882354],\n",
       "        [0.75686276],\n",
       "        [0.7019608 ],\n",
       "        [0.67058825],\n",
       "        [0.7176471 ],\n",
       "        [0.76862746],\n",
       "        [0.8       ],\n",
       "        [0.8235294 ],\n",
       "        [0.8352941 ],\n",
       "        [0.8117647 ],\n",
       "        [0.827451  ],\n",
       "        [0.8235294 ],\n",
       "        [0.78431374],\n",
       "        [0.76862746],\n",
       "        [0.7607843 ],\n",
       "        [0.7490196 ],\n",
       "        [0.7647059 ],\n",
       "        [0.7490196 ],\n",
       "        [0.7764706 ],\n",
       "        [0.7529412 ],\n",
       "        [0.6901961 ],\n",
       "        [0.6117647 ],\n",
       "        [0.654902  ],\n",
       "        [0.69411767],\n",
       "        [0.8235294 ],\n",
       "        [0.36078432]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.2901961 ],\n",
       "        [0.7411765 ],\n",
       "        [0.83137256],\n",
       "        [0.7490196 ],\n",
       "        [0.6862745 ],\n",
       "        [0.6745098 ],\n",
       "        [0.6862745 ],\n",
       "        [0.70980394],\n",
       "        [0.7254902 ],\n",
       "        [0.7372549 ],\n",
       "        [0.7411765 ],\n",
       "        [0.7372549 ],\n",
       "        [0.75686276],\n",
       "        [0.7764706 ],\n",
       "        [0.8       ],\n",
       "        [0.81960785],\n",
       "        [0.8235294 ],\n",
       "        [0.8235294 ],\n",
       "        [0.827451  ],\n",
       "        [0.7372549 ],\n",
       "        [0.7372549 ],\n",
       "        [0.7607843 ],\n",
       "        [0.7529412 ],\n",
       "        [0.84705883],\n",
       "        [0.6666667 ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.00784314],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.25882354],\n",
       "        [0.78431374],\n",
       "        [0.87058824],\n",
       "        [0.92941177],\n",
       "        [0.9372549 ],\n",
       "        [0.9490196 ],\n",
       "        [0.9647059 ],\n",
       "        [0.9529412 ],\n",
       "        [0.95686275],\n",
       "        [0.8666667 ],\n",
       "        [0.8627451 ],\n",
       "        [0.75686276],\n",
       "        [0.7490196 ],\n",
       "        [0.7019608 ],\n",
       "        [0.7137255 ],\n",
       "        [0.7137255 ],\n",
       "        [0.70980394],\n",
       "        [0.6901961 ],\n",
       "        [0.6509804 ],\n",
       "        [0.65882355],\n",
       "        [0.3882353 ],\n",
       "        [0.22745098],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.15686275],\n",
       "        [0.23921569],\n",
       "        [0.17254902],\n",
       "        [0.28235295],\n",
       "        [0.16078432],\n",
       "        [0.13725491],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers , models \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mohamed osama\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), input_shape=(28, 28,1)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D (64 , (3 , 3) , activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D (64 , (3 , 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(10 , activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,770</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m5,770\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">61,514</span> (240.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m61,514\u001b[0m (240.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">61,514</span> (240.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m61,514\u001b[0m (240.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate=0.1), loss = 'sparse_categorical_crossentropy' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.5781 - loss: 1.2145 - val_accuracy: 0.7941 - val_loss: 0.5641\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.8149 - loss: 0.5052 - val_accuracy: 0.8339 - val_loss: 0.4595\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.8438 - loss: 0.4296 - val_accuracy: 0.8510 - val_loss: 0.4046\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.8581 - loss: 0.3848 - val_accuracy: 0.8644 - val_loss: 0.3792\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.8663 - loss: 0.3634 - val_accuracy: 0.8652 - val_loss: 0.3739\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8742 - loss: 0.3390 - val_accuracy: 0.8639 - val_loss: 0.3698\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.8834 - loss: 0.3226 - val_accuracy: 0.8809 - val_loss: 0.3291\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.8844 - loss: 0.3168 - val_accuracy: 0.8819 - val_loss: 0.3258\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.8899 - loss: 0.3008 - val_accuracy: 0.8744 - val_loss: 0.3450\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.8938 - loss: 0.2887 - val_accuracy: 0.8874 - val_loss: 0.3112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1ada8bb1dd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels , epochs= 10 , batch_size=128 ,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8711 - loss: 0.3928\n"
     ]
    }
   ],
   "source": [
    "test_loss , test_accuracy = model.evaluate(test_images , test_labels)\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9), loss = 'sparse_categorical_crossentropy' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.8470 - loss: 0.4299 - val_accuracy: 0.8715 - val_loss: 0.3596\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.8731 - loss: 0.3481 - val_accuracy: 0.8717 - val_loss: 0.3474\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.8845 - loss: 0.3132 - val_accuracy: 0.8706 - val_loss: 0.3598\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.8894 - loss: 0.2989 - val_accuracy: 0.8801 - val_loss: 0.3315\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.8948 - loss: 0.2890 - val_accuracy: 0.8702 - val_loss: 0.3721\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9025 - loss: 0.2654 - val_accuracy: 0.8812 - val_loss: 0.3345\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9077 - loss: 0.2541 - val_accuracy: 0.8892 - val_loss: 0.3293\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9087 - loss: 0.2418 - val_accuracy: 0.8960 - val_loss: 0.3077\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9148 - loss: 0.2281 - val_accuracy: 0.8809 - val_loss: 0.3539\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9155 - loss: 0.2269 - val_accuracy: 0.8832 - val_loss: 0.3439\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1ada89f80d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels , epochs= 10 , batch_size=128 ,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True), loss = 'sparse_categorical_crossentropy' , metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.5891 - loss: 1.2661 - val_accuracy: 0.8123 - val_loss: 0.5152\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.8210 - loss: 0.4843 - val_accuracy: 0.8386 - val_loss: 0.4437\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.8526 - loss: 0.4126 - val_accuracy: 0.8602 - val_loss: 0.3840\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.8670 - loss: 0.3704 - val_accuracy: 0.8717 - val_loss: 0.3549\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.8788 - loss: 0.3411 - val_accuracy: 0.8731 - val_loss: 0.3542\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.8833 - loss: 0.3241 - val_accuracy: 0.8838 - val_loss: 0.3273\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.8872 - loss: 0.3081 - val_accuracy: 0.8857 - val_loss: 0.3176\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.8918 - loss: 0.2956 - val_accuracy: 0.8874 - val_loss: 0.3119\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.8989 - loss: 0.2778 - val_accuracy: 0.8903 - val_loss: 0.3050\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9020 - loss: 0.2668 - val_accuracy: 0.8905 - val_loss: 0.3067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1adb0719090>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels , epochs= 10 , batch_size=128 ,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='RMSprop', loss = 'sparse_categorical_crossentropy' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.8895 - loss: 0.3016 - val_accuracy: 0.8932 - val_loss: 0.3014\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.8991 - loss: 0.2771 - val_accuracy: 0.8876 - val_loss: 0.3184\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9067 - loss: 0.2590 - val_accuracy: 0.8896 - val_loss: 0.3131\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9121 - loss: 0.2425 - val_accuracy: 0.9002 - val_loss: 0.2813\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9185 - loss: 0.2299 - val_accuracy: 0.9045 - val_loss: 0.2751\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9205 - loss: 0.2186 - val_accuracy: 0.9007 - val_loss: 0.2844\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9226 - loss: 0.2126 - val_accuracy: 0.9062 - val_loss: 0.2657\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9310 - loss: 0.1927 - val_accuracy: 0.8998 - val_loss: 0.3058\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9340 - loss: 0.1810 - val_accuracy: 0.8829 - val_loss: 0.3114\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9376 - loss: 0.1693 - val_accuracy: 0.9048 - val_loss: 0.2698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1adb4455110>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels , epochs= 10 , batch_size=128 ,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9383 - loss: 0.1661 - val_accuracy: 0.9033 - val_loss: 0.2930\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9467 - loss: 0.1471 - val_accuracy: 0.9053 - val_loss: 0.2840\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9491 - loss: 0.1394 - val_accuracy: 0.8997 - val_loss: 0.3061\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9515 - loss: 0.1340 - val_accuracy: 0.9087 - val_loss: 0.2793\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9561 - loss: 0.1217 - val_accuracy: 0.9087 - val_loss: 0.2889\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9582 - loss: 0.1148 - val_accuracy: 0.9058 - val_loss: 0.2886\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9589 - loss: 0.1130 - val_accuracy: 0.9080 - val_loss: 0.3087\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9624 - loss: 0.1035 - val_accuracy: 0.9092 - val_loss: 0.3133\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9663 - loss: 0.0933 - val_accuracy: 0.9033 - val_loss: 0.3260\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9690 - loss: 0.0883 - val_accuracy: 0.9053 - val_loss: 0.3344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1adb4435410>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels , epochs= 10 , batch_size=128 ,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models, regularizers, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mohamed osama\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(0.02),input_shape=(28, 28,1)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv2D (64 , (3 , 3),kernel_regularizer=regularizers.l2(0.02) , activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D (64 , (3 , 3),kernel_regularizer=regularizers.l2(0.02), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(10 , activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,770</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m5,770\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">61,642</span> (240.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m61,642\u001b[0m (240.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">61,578</span> (240.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m61,578\u001b[0m (240.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> (256.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m64\u001b[0m (256.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate=0.1), loss = 'sparse_categorical_crossentropy' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.7198 - loss: 0.8225 - val_accuracy: 0.8283 - val_loss: 0.8056\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.8492 - loss: 0.4310 - val_accuracy: 0.8608 - val_loss: 0.3942\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - accuracy: 0.8654 - loss: 0.3824 - val_accuracy: 0.8733 - val_loss: 0.3608\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.8806 - loss: 0.3442 - val_accuracy: 0.8807 - val_loss: 0.3444\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.8903 - loss: 0.3239 - val_accuracy: 0.8631 - val_loss: 0.3993\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.8914 - loss: 0.3132 - val_accuracy: 0.8753 - val_loss: 0.3522\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.8949 - loss: 0.3033 - val_accuracy: 0.8898 - val_loss: 0.3191\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.8971 - loss: 0.2885 - val_accuracy: 0.8915 - val_loss: 0.3204\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.9031 - loss: 0.2791 - val_accuracy: 0.8942 - val_loss: 0.3012\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.9047 - loss: 0.2756 - val_accuracy: 0.8936 - val_loss: 0.3063\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1add2bf7b50>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels , epochs= 10 , batch_size=128 ,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9), loss = 'sparse_categorical_crossentropy' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.7891 - loss: 0.7064 - val_accuracy: 0.7178 - val_loss: 0.7609\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.8322 - loss: 0.4872 - val_accuracy: 0.8533 - val_loss: 0.4391\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.8486 - loss: 0.4437 - val_accuracy: 0.8355 - val_loss: 0.4713\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.8510 - loss: 0.4411 - val_accuracy: 0.7868 - val_loss: 0.6234\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.8576 - loss: 0.4206 - val_accuracy: 0.8565 - val_loss: 0.4119\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - accuracy: 0.8579 - loss: 0.4136 - val_accuracy: 0.8647 - val_loss: 0.3983\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.8658 - loss: 0.3993 - val_accuracy: 0.8367 - val_loss: 0.4871\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.8600 - loss: 0.4104 - val_accuracy: 0.8669 - val_loss: 0.4040\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - accuracy: 0.8700 - loss: 0.3802 - val_accuracy: 0.8461 - val_loss: 0.4305\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.8691 - loss: 0.3896 - val_accuracy: 0.8733 - val_loss: 0.3734\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1adbfb7aed0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels , epochs= 10 , batch_size=128 ,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True), loss = 'sparse_categorical_crossentropy' , metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.8894 - loss: 0.3202 - val_accuracy: 0.8913 - val_loss: 0.3075\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.9006 - loss: 0.2761 - val_accuracy: 0.8938 - val_loss: 0.3013\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - accuracy: 0.9057 - loss: 0.2585 - val_accuracy: 0.8947 - val_loss: 0.2977\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.9053 - loss: 0.2616 - val_accuracy: 0.8937 - val_loss: 0.2947\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.9066 - loss: 0.2587 - val_accuracy: 0.8967 - val_loss: 0.2936\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.9064 - loss: 0.2567 - val_accuracy: 0.8938 - val_loss: 0.2953\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.9074 - loss: 0.2512 - val_accuracy: 0.8961 - val_loss: 0.2962\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - accuracy: 0.9086 - loss: 0.2473 - val_accuracy: 0.8970 - val_loss: 0.2908\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.9144 - loss: 0.2420 - val_accuracy: 0.8982 - val_loss: 0.2900\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.9132 - loss: 0.2409 - val_accuracy: 0.8981 - val_loss: 0.2874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1adb433e810>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels , epochs= 10 , batch_size=128 ,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='RMSprop', loss = 'sparse_categorical_crossentropy' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.7368 - loss: 1.8316 - val_accuracy: 0.8160 - val_loss: 1.0377\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.8351 - loss: 0.6000 - val_accuracy: 0.8497 - val_loss: 0.5493\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.8528 - loss: 0.5296 - val_accuracy: 0.8512 - val_loss: 0.5164\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.8615 - loss: 0.4929 - val_accuracy: 0.8672 - val_loss: 0.4709\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.8669 - loss: 0.4696 - val_accuracy: 0.8737 - val_loss: 0.4564\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.8688 - loss: 0.4561 - val_accuracy: 0.8658 - val_loss: 0.4615\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.8715 - loss: 0.4439 - val_accuracy: 0.8659 - val_loss: 0.4588\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.8723 - loss: 0.4390 - val_accuracy: 0.8626 - val_loss: 0.4698\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.8762 - loss: 0.4335 - val_accuracy: 0.8701 - val_loss: 0.4487\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.8771 - loss: 0.4270 - val_accuracy: 0.8694 - val_loss: 0.4377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1adca1f2ed0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels , epochs= 10 , batch_size=128 ,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.8816 - loss: 0.4168 - val_accuracy: 0.8652 - val_loss: 0.4481\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.8867 - loss: 0.4009 - val_accuracy: 0.8823 - val_loss: 0.4148\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.8852 - loss: 0.4041 - val_accuracy: 0.8727 - val_loss: 0.4333\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.8853 - loss: 0.3994 - val_accuracy: 0.8798 - val_loss: 0.4158\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.8859 - loss: 0.3963 - val_accuracy: 0.8831 - val_loss: 0.4070\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.8864 - loss: 0.3956 - val_accuracy: 0.8771 - val_loss: 0.4181\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.8893 - loss: 0.3861 - val_accuracy: 0.8764 - val_loss: 0.4208\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.8884 - loss: 0.3835 - val_accuracy: 0.8808 - val_loss: 0.4135\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.8866 - loss: 0.3930 - val_accuracy: 0.8767 - val_loss: 0.4113\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.8906 - loss: 0.3855 - val_accuracy: 0.8841 - val_loss: 0.4007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1adb12dac10>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels , epochs= 10 , batch_size=128 ,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout , BatchNormalization\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers, models, regularizers, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential([\n",
    "    Conv2D(32, (3, 3), padding='same'  ,activation='relu', kernel_regularizer=regularizers.l2(hp.Float('l2_reg', min_value=0.0005, max_value=0.5, sampling='LOG')), input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), padding='same' ,kernel_regularizer=regularizers.l2(hp.Float('l2_reg', min_value=0.0005, max_value=0.5, sampling='LOG')) ,activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(hp.Float('l2_reg', min_value=0.0005, max_value=0.5, sampling='LOG')) ,activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(hp.Float('l2_reg', min_value=0.0005, max_value=0.5, sampling='LOG')), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dropout(hp.Float('dropout', min_value=0.3, max_value=0.7, step=0.1)),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "    model.compile(\n",
    "        optimizer=hp.Choice('optimizer', values=['adam', 'rmsprop','SGD' ,' tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)','Nadam']),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras_tuner\n",
      "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: keras in c:\\users\\mohamed osama\\anaconda3\\lib\\site-packages (from keras_tuner) (3.4.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\mohamed osama\\anaconda3\\lib\\site-packages (from keras_tuner) (23.1)\n",
      "Requirement already satisfied: requests in c:\\users\\mohamed osama\\anaconda3\\lib\\site-packages (from keras_tuner) (2.31.0)\n",
      "Collecting kt-legacy (from keras_tuner)\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
      "Requirement already satisfied: absl-py in c:\\users\\mohamed osama\\anaconda3\\lib\\site-packages (from keras->keras_tuner) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\mohamed osama\\anaconda3\\lib\\site-packages (from keras->keras_tuner) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\mohamed osama\\anaconda3\\lib\\site-packages (from keras->keras_tuner) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\mohamed osama\\anaconda3\\lib\\site-packages (from keras->keras_tuner) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\mohamed osama\\anaconda3\\lib\\site-packages (from keras->keras_tuner) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\mohamed osama\\anaconda3\\lib\\site-packages (from keras->keras_tuner) (0.12.1)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\mohamed osama\\anaconda3\\lib\\site-packages (from keras->keras_tuner) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mohamed osama\\anaconda3\\lib\\site-packages (from requests->keras_tuner) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mohamed osama\\anaconda3\\lib\\site-packages (from requests->keras_tuner) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mohamed osama\\anaconda3\\lib\\site-packages (from requests->keras_tuner) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mohamed osama\\anaconda3\\lib\\site-packages (from requests->keras_tuner) (2024.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\mohamed osama\\anaconda3\\lib\\site-packages (from optree->keras->keras_tuner) (4.9.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\mohamed osama\\anaconda3\\lib\\site-packages (from rich->keras->keras_tuner) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mohamed osama\\anaconda3\\lib\\site-packages (from rich->keras->keras_tuner) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\mohamed osama\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras->keras_tuner) (0.1.0)\n",
      "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
      "   ---------------------------------------- 0.0/129.1 kB ? eta -:--:--\n",
      "   ------ -------------------------------- 20.5/129.1 kB 640.0 kB/s eta 0:00:01\n",
      "   --------------- ----------------------- 51.2/129.1 kB 650.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 129.1/129.1 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: kt-legacy, keras_tuner\n",
      "Successfully installed keras_tuner-1.4.7 kt-legacy-1.0.5\n"
     ]
    }
   ],
   "source": [
    "! pip install keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from My Codes\\fashion_mnist\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=50,\n",
    "    executions_per_trial=1,\n",
    "    directory='My Codes',\n",
    "    project_name='fashion_mnist'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 02m 29s]\n",
      "val_accuracy: 0.9107999801635742\n",
      "\n",
      "Best val_accuracy So Far: 0.9174000024795532\n",
      "Total elapsed time: 2d 22h 46m 51s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mohamed osama\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
